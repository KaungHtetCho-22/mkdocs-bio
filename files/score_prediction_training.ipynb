{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1869cb-da5e-4f53-b8fc-476a094e820d",
   "metadata": {},
   "source": [
    "# **Biodiversity Score Level Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c2225-4510-4eb3-8bd8-76296a210c2c",
   "metadata": {},
   "source": [
    "This notebook offers a step-by-step guide for training a model to predict biodiversity score levels, using a pivot table generated from audio classification results.  \n",
    "\n",
    "## Workflow\n",
    "- [Setup](#Setup): Installing necessary Python libraries.\n",
    "- [Data Preprocessing](#Data-Preprocessing): Clean, transform, and prepare the dataset for model training.\n",
    "- [Model Training](#Model-Training): Build and train the prediction model on the processed data.\n",
    "- [Inference and Prediction](#Inference-and-Prediction): Use the trained model to make predictions on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b13c3-9def-493e-9e1d-87b618ef96b0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c0bda7-0a2e-45f3-a1db-0cd95bd69f03",
   "metadata": {},
   "source": [
    "### Requirement\n",
    "- Python3.10 and above\n",
    "- numpy\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- xgboost\n",
    "- seaborn\n",
    "- matplotlib\n",
    "\n",
    "The Python libraries can be installed using pip. eg. `pip install numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c68c02-2833-4fe2-bc2e-4e275ec479cf",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3f5b8-633c-45fc-8e50-98505a9e16ea",
   "metadata": {},
   "source": [
    "- The audio classification predictions serve as the training data for predicting biodiversity scores. They are found in the `./data/csv`.\n",
    "- A pivot table is used to convert the audio classification predictions into the frequency of appearance for each species. This can be done by simply running the following code in the command line at the current directory, and the output will be `pivot_table.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cdc04e-5bdc-4600-bd8c-a7ce14da960a",
   "metadata": {},
   "source": [
    "`python3` preprocess.py --csv_path ./data/csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154bbcea-0912-4ed6-8e8e-abd1e9753d3d",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e2ca1-535f-4e8b-a129-acbad32b37e4",
   "metadata": {},
   "source": [
    "- An XGBoost classification model is used to predict the biodiversity score level.\n",
    "\n",
    "- The data is first split into training and testing (validation) sets and then normalized using the `StandardScaler` function from the scikit-learn library.\n",
    "\n",
    "- The objective function is to minimize the cross-entropy loss (logloss) between the ground truth and the predictions.\n",
    "\n",
    "- `GridSearch` is used for hyperparameter optimization. The optimal number of features is determined using recursive feature elimination, comparing models with 20, 30, 40, 50, 60, 70, and 80 features.\n",
    "\n",
    "- Below command is for model training and validation.\n",
    "\n",
    "- Trained model weights are saved in `./results/weights` in best_xgboost_model_{`num_feature`}_{`acc`}_f1_{`f1score`}.pkl format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c682a4-1205-4874-963f-592a7ad13b32",
   "metadata": {},
   "source": [
    "`python3` training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac5522-ade2-4731-9bd7-a575b53a8b28",
   "metadata": {},
   "source": [
    "The image below shows an example of the training output, which includes a list of the selected features and the corresponding classification report for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed999e15-ecde-49be-ade3-da08fb0f53e0",
   "metadata": {},
   "source": [
    "<img src=\"data/bio_score_training.png\" alt=\"bio_score_training\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9759aab8-4543-40d9-aa1b-3e7143a34164",
   "metadata": {},
   "source": [
    "### Inference and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344450d-dd73-4f9e-a27f-e79f0bac1b3e",
   "metadata": {},
   "source": [
    "`python3 preprocess_unseen_data.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe8ed7-66c1-45fe-a822-5ed14e59939c",
   "metadata": {},
   "source": [
    "##### Preprocess Unseen Data\n",
    "The unseen(test) data is preprocessed and converted into pivot table using the following command. You can modify the filepath inside the code. The pivot table is saved in `forestia_processed_df.csv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d67061-8a42-4849-9b53-3cec46808d93",
   "metadata": {},
   "source": [
    "##### Prediction\n",
    "- Copy and paste the selected features obtained from the training.\n",
    "- Modify the model weight file location.\n",
    "- Modify the preprocessed data file location.\n",
    "- Execute the following command.\n",
    "- If there is a `KeyError` shows up, new columns with value 0 have to be added. Example, `df['Acheta-domesticus'] = 0`\n",
    "- The prediction result for each example is appended into the dataframe and saved in `bioscore_predictions.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065a664-0ae3-4104-9e25-1e1e2efccb62",
   "metadata": {},
   "source": [
    "`python3 predict.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04cfceb-6ae8-4ec2-9b1e-041237b3a2ad",
   "metadata": {},
   "source": [
    "<img src=\"data/final_score.png\" alt=\"bio_score_training\" width=\"300\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
