{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Biodiversity \u00b6 Welcome to the Biodiversity Project Documentation . This guide provides detailed instructions, references, and technical explanations for setting up the hardware, training AI models, running inference pipelines, and displaying results on the web. 1. Hardware Components \u00b6 This section explains how to set up the hardware used in the project and configure the necessary scripts to start operations. Step-by-step installation and configuration Overview of IoT devices and their roles Key scripts and commands for operation Read more \u2192 2. AI Models \u00b6 This section describes the AI models developed for biodiversity monitoring, including sound classification and score prediction . 2.1. Overview Procedure \u00b6 General workflow for model training and evaluation. 2.2. Sound Classification / Training \u00b6 Data preparation and preprocessing Model architecture and training parameters Evaluation metrics 2.3. Score Prediction / Training \u00b6 Feature engineering Model training and validation Performance monitoring Read more \u2192 3. Inference \u00b6 This section explains how the system performs inference and serves results. 3.1. Overview Procedure \u00b6 High-level inference workflow. 3.2. Database Design \u00b6 Schema design and data storage strategy. 3.3. Inference Pipeline Design \u00b6 Step-by-step data flow for predictions. 3.4. Results Showing on the Web \u00b6 Web UI integration for visualizing predictions and analytics. Read more \u2192 About This Documentation \u00b6 This documentation is part of the Biodiversity Project , which aims to automate biodiversity monitoring using IoT devices, AI-driven sound classification, and real-time score predictions. It is organized for developers, researchers, and field operators to follow consistently from setup to deployment. All the source code are pushed to the github","title":"Home"},{"location":"#biodiversity","text":"Welcome to the Biodiversity Project Documentation . This guide provides detailed instructions, references, and technical explanations for setting up the hardware, training AI models, running inference pipelines, and displaying results on the web.","title":"Biodiversity"},{"location":"#1-hardware-components","text":"This section explains how to set up the hardware used in the project and configure the necessary scripts to start operations. Step-by-step installation and configuration Overview of IoT devices and their roles Key scripts and commands for operation Read more \u2192","title":"1. Hardware Components"},{"location":"#2-ai-models","text":"This section describes the AI models developed for biodiversity monitoring, including sound classification and score prediction .","title":"2. AI Models"},{"location":"#21-overview-procedure","text":"General workflow for model training and evaluation.","title":"2.1. Overview Procedure"},{"location":"#22-sound-classification-training","text":"Data preparation and preprocessing Model architecture and training parameters Evaluation metrics","title":"2.2. Sound Classification / Training"},{"location":"#23-score-prediction-training","text":"Feature engineering Model training and validation Performance monitoring Read more \u2192","title":"2.3. Score Prediction / Training"},{"location":"#3-inference","text":"This section explains how the system performs inference and serves results.","title":"3. Inference"},{"location":"#31-overview-procedure","text":"High-level inference workflow.","title":"3.1. Overview Procedure"},{"location":"#32-database-design","text":"Schema design and data storage strategy.","title":"3.2. Database Design"},{"location":"#33-inference-pipeline-design","text":"Step-by-step data flow for predictions.","title":"3.3. Inference Pipeline Design"},{"location":"#34-results-showing-on-the-web","text":"Web UI integration for visualizing predictions and analytics. Read more \u2192","title":"3.4. Results Showing on the Web"},{"location":"#about-this-documentation","text":"This documentation is part of the Biodiversity Project , which aims to automate biodiversity monitoring using IoT devices, AI-driven sound classification, and real-time score predictions. It is organized for developers, researchers, and field operators to follow consistently from setup to deployment. All the source code are pushed to the github","title":"About This Documentation"},{"location":"ai/","text":"AI Models \u00b6 The AI module in the Biodiversity Project is composed of two main parts: Sound Classification System Identifies bird and insect species, as well as noise categories, from recorded audio. Score Prediction Model Generates a biodiversity score based on the outputs of the sound classification system. Sound Model Training \u00b6 This section describes the process and details for training the sound classification model. 1. Training Dataset \u00b6 The dataset consists of bird species , insect species , and noise classes . 1.1 Bird Species \u00b6 Common Name Biological Name Number of Samples Asian Koel Eudynamys scolopaceus 1200 (Add more rows here) 1.2 Insect Species \u00b6 Common Name Biological Name Number of Samples Cicada Cicadidae 800 (Add more rows here) 1.3 Noise Classes \u00b6 Class Name Description Number of Samples (Example) Rain Background rain noise 500 (Add more rows here) 2. Model Accuracy \u00b6 Metric Value Accuracy XX% Precision XX% Recall XX% F1-Score XX% (Replace XX% with actual results after training.) 3. Model Architecture \u00b6 The sound classification system is based on: Input: Mel-spectrograms extracted from audio recordings. Feature Extraction: Convolutional Neural Networks (CNNs) for spatial feature learning. Classification Layer: Fully-connected layers with softmax output for multi-class classification. Training Details: Optimizer: Adam Loss: Categorical Cross-Entropy Learning Rate: (e.g., 0.001) Epochs: (e.g., 50) Batch Size: (e.g., 32) Next: Score Prediction Model","title":"AI Models"},{"location":"ai/#ai-models","text":"The AI module in the Biodiversity Project is composed of two main parts: Sound Classification System Identifies bird and insect species, as well as noise categories, from recorded audio. Score Prediction Model Generates a biodiversity score based on the outputs of the sound classification system.","title":"AI Models"},{"location":"ai/#sound-model-training","text":"This section describes the process and details for training the sound classification model.","title":"Sound Model Training"},{"location":"ai/#1-training-dataset","text":"The dataset consists of bird species , insect species , and noise classes .","title":"1. Training Dataset"},{"location":"ai/#11-bird-species","text":"Common Name Biological Name Number of Samples Asian Koel Eudynamys scolopaceus 1200 (Add more rows here)","title":"1.1 Bird Species"},{"location":"ai/#12-insect-species","text":"Common Name Biological Name Number of Samples Cicada Cicadidae 800 (Add more rows here)","title":"1.2 Insect Species"},{"location":"ai/#13-noise-classes","text":"Class Name Description Number of Samples (Example) Rain Background rain noise 500 (Add more rows here)","title":"1.3 Noise Classes"},{"location":"ai/#2-model-accuracy","text":"Metric Value Accuracy XX% Precision XX% Recall XX% F1-Score XX% (Replace XX% with actual results after training.)","title":"2. Model Accuracy"},{"location":"ai/#3-model-architecture","text":"The sound classification system is based on: Input: Mel-spectrograms extracted from audio recordings. Feature Extraction: Convolutional Neural Networks (CNNs) for spatial feature learning. Classification Layer: Fully-connected layers with softmax output for multi-class classification. Training Details: Optimizer: Adam Loss: Categorical Cross-Entropy Learning Rate: (e.g., 0.001) Epochs: (e.g., 50) Batch Size: (e.g., 32) Next: Score Prediction Model","title":"3. Model Architecture"},{"location":"data/","text":"This is the data augmentation documentation \u00b6","title":"Data"},{"location":"data/#this-is-the-data-augmentation-documentation","text":"","title":"This is the data augmentation documentation"},{"location":"hardware/","text":"Hardware Components Documentation \u00b6 1. IoT Device List \u00b6 The following devices are used in the system: Raspberry Pi AudioMoth 4G Router Internet SIM Card Solar Panel 2. Raspberry Pi \u2014 OS & Installation \u00b6 Model: Raspberry Pi 3 B+ Storage: 64 GB microSD card Setup: Flash the backup OS image to the new SD card. Installation Process: 1. Insert the SD card into your computer. 2. Use an imaging tool (e.g., Balena Etcher) to flash the backup .img file. 3. Insert the flashed SD card into the Raspberry Pi. 4. Power on the device. 2.1. Important Scripts & Files \u00b6 The Raspberry Pi OS contains key scripts and configurations: File / Service Description recorder-script.sh Main script to handle audio recording. config.json Configuration file for device parameters. OpenVPN installation (UI) Provides secure remote access. journalctl -u shellscript.service -f Command to check live service logs. arecord -l Command to list available recording devices. 3. AudioMoth Device \u00b6 The AudioMoth is used for audio data collection in two modes : Download Audiomoth setup manual PDF Download Whole IOT device setup PDF version 3.1. Mobile Type Usage \u00b6 Portable configuration for temporary deployments. Ideal for short-term surveys. (Insert images here) 3.2. Station Type Usage \u00b6 Fixed position setup for continuous monitoring. Powered by solar or external battery. (Insert images here) 4. Router Status \u00b6 Type: 4G Router Function: Provides internet connectivity via SIM card. Troubleshooting: - Check LED status indicators. - Ensure SIM card is active. - Restart router if connection drops. 5. Solar Panel Status \u00b6 Purpose: Supplies power to IoT devices in remote areas. Indicators: - Green light: Charging - Red light: Low battery - Off: No power supply (Insert detailed specifications here) 6. Battery Status \u00b6 Purpose: Stores energy for nighttime or cloudy-day operation. LED/Blink Indicators: - 1 blink: Low power - 2 blinks: Medium - 3 blinks: Fully charged (Insert battery photos here) 7. Overall Working Flow \u00b6 Power Supply: Solar panel \u2192 Battery \u2192 Raspberry Pi + Router. Data Capture: AudioMoth / Pi records data. Data Transmission: Router sends data over 4G network. Remote Access: OpenVPN connection to retrieve/manage data. Monitoring: Logs checked via journalctl or SSH commands. (Insert workflow diagram here)","title":"Hardware Components Documentation"},{"location":"hardware/#hardware-components-documentation","text":"","title":"Hardware Components Documentation"},{"location":"hardware/#1-iot-device-list","text":"The following devices are used in the system: Raspberry Pi AudioMoth 4G Router Internet SIM Card Solar Panel","title":"1. IoT Device List"},{"location":"hardware/#2-raspberry-pi-os-installation","text":"Model: Raspberry Pi 3 B+ Storage: 64 GB microSD card Setup: Flash the backup OS image to the new SD card. Installation Process: 1. Insert the SD card into your computer. 2. Use an imaging tool (e.g., Balena Etcher) to flash the backup .img file. 3. Insert the flashed SD card into the Raspberry Pi. 4. Power on the device.","title":"2. Raspberry Pi \u2014 OS &amp; Installation"},{"location":"hardware/#21-important-scripts-files","text":"The Raspberry Pi OS contains key scripts and configurations: File / Service Description recorder-script.sh Main script to handle audio recording. config.json Configuration file for device parameters. OpenVPN installation (UI) Provides secure remote access. journalctl -u shellscript.service -f Command to check live service logs. arecord -l Command to list available recording devices.","title":"2.1. Important Scripts &amp; Files"},{"location":"hardware/#3-audiomoth-device","text":"The AudioMoth is used for audio data collection in two modes : Download Audiomoth setup manual PDF Download Whole IOT device setup PDF version","title":"3. AudioMoth Device"},{"location":"hardware/#31-mobile-type-usage","text":"Portable configuration for temporary deployments. Ideal for short-term surveys. (Insert images here)","title":"3.1. Mobile Type Usage"},{"location":"hardware/#32-station-type-usage","text":"Fixed position setup for continuous monitoring. Powered by solar or external battery. (Insert images here)","title":"3.2. Station Type Usage"},{"location":"hardware/#4-router-status","text":"Type: 4G Router Function: Provides internet connectivity via SIM card. Troubleshooting: - Check LED status indicators. - Ensure SIM card is active. - Restart router if connection drops.","title":"4. Router Status"},{"location":"hardware/#5-solar-panel-status","text":"Purpose: Supplies power to IoT devices in remote areas. Indicators: - Green light: Charging - Red light: Low battery - Off: No power supply (Insert detailed specifications here)","title":"5. Solar Panel Status"},{"location":"hardware/#6-battery-status","text":"Purpose: Stores energy for nighttime or cloudy-day operation. LED/Blink Indicators: - 1 blink: Low power - 2 blinks: Medium - 3 blinks: Fully charged (Insert battery photos here)","title":"6. Battery Status"},{"location":"hardware/#7-overall-working-flow","text":"Power Supply: Solar panel \u2192 Battery \u2192 Raspberry Pi + Router. Data Capture: AudioMoth / Pi records data. Data Transmission: Router sends data over 4G network. Remote Access: OpenVPN connection to retrieve/manage data. Monitoring: Logs checked via journalctl or SSH commands. (Insert workflow diagram here)","title":"7. Overall Working Flow"},{"location":"inference/","text":"This is how inference pipeline setup on iNET \u00b6 This is how the conceptual diagram works inside the inference data accepting","title":"Inference"},{"location":"inference/#this-is-how-inference-pipeline-setup-on-inet","text":"This is how the conceptual diagram works inside the inference data accepting","title":"This is how inference pipeline setup on iNET"},{"location":"notes/","text":"This is the some important notes to take care of \u00b6","title":"Notes"},{"location":"notes/#this-is-the-some-important-notes-to-take-care-of","text":"","title":"This is the some important notes to take care of"},{"location":"score/","text":"This is the documentation for the score prediction model \u00b6","title":"Score"},{"location":"score/#this-is-the-documentation-for-the-score-prediction-model","text":"","title":"This is the documentation for the score prediction model"},{"location":"training/","text":"This is the model training documentation \u00b6","title":"Training"},{"location":"training/#this-is-the-model-training-documentation","text":"","title":"This is the model training documentation"}]}